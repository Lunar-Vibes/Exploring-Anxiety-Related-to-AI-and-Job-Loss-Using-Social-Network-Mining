################################################################################
# Applied Finance (Risk Modelling) - Shagufta(477654)
# Exercise 1.1
################################################################################
install.packages("GAS")
library(xts)
library(ggplot2)
library(utils)
library(rugarch)
#library(GAS)
install.packages("xts")   # run once if not installed
library(xts)


getwd()
#setwd("C:\\Users\\shahe\\AF\\prof 3\\HW\\HW")


index_data <- read.csv("lse.csv", stringsAsFactors = F)
index_data.xts <- xts(index_data[,-1],as.Date(index_data[, 1], "%Y-%m-%d"))

p_value <- 0.025
forecast_horizon <- 250

log_returns <- diff(log(index_data.xts$Zamkniecie), lag = 1)

data <- log_returns["2018/2021"]

nrow(data)

training_sample_len <- nrow(data) - forecast_horizon

plot(data)
addEventLines(
  events = xts("testing sample", index(data[nrow(data) - forecast_horizon + 1])),
  col = "red",
  srt = 270,
  pos = 4
)
#########################################
#Historical simulation
########################################
rollHS <- rollapplyr(data, training_sample_len,
                     function(w) {
                       quantile(w, p_value)
                     })

testHS <- last(lag(rollHS, 1), 250)

#######################################
#Garch (normal)
#######################################

specnorm <-
  ugarchspec(
    variance.model = list(model="sGARCH", garchOrder=c(1, 1)),
    mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
    distribution.model = 'norm'
  )

rollnorm <- ugarchroll(
  specnorm,
  data,
  n.ahead = 1,
  forecast.length = forecast_horizon,
  refit.every = 1,
  refit.window = 'moving',
  keep.coef = TRUE,
  calculate.VaR = TRUE,
  VaR.alpha = p_value
)

testGarchNORM <- xts(rollnorm@forecast$VaR,
                     as.Date(rownames(rollnorm@forecast$VaR)))[, 1]

plot(cbind(last(data, 250), rollnorm@forecast$density$Sigma))

# GARCH model specification
specSnorm <-
  ugarchspec(
    variance.model = list(model="sGARCH", garchOrder=c(1, 1)),
    mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
    distribution.model = 'snorm'
  )

# Rolling window approach estimation
rollSnorm <-
  ugarchroll(
    specSnorm,
    data,
    n.ahead = 1,
    forecast.length = forecast_horizon,
    refit.every = 1,
    refit.window = 'moving',
    keep.coef = TRUE,
    calculate.VaR = TRUE,
    VaR.alpha = p_value
  )

testGarchSNORM <- xts(rollSnorm@forecast$VaR,
                      as.Date(rownames(rollSnorm@forecast$VaR)))[, 1]

plot(cbind(last(data, 250), rollSnorm@forecast$density$Sigma))

############################################
# GARCH(1,1) with skewed t distribution
###########################################
specSt <-
  ugarchspec(
    variance.model = list(model="sGARCH", garchOrder=c(1, 1)),
    mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
    distribution.model = 'sstd'
  )

rollst <-
  ugarchroll(
    specSt,
    data,
    n.ahead = 1,
    forecast.length = forecast_horizon,
    refit.every = 1,
    refit.window = 'moving',
    keep.coef = TRUE,
    calculate.VaR = TRUE,
    VaR.alpha = p_value
  )

testGarchST <- xts(rollst@forecast$VaR,
                   as.Date(rownames(rollnorm@forecast$VaR)))[, 1]

plot(cbind(last(data, 250), rollst@forecast$density$Sigma))

########################################
# Filtered Historical Simulation (by GARCH(1,1))
########################################
rollFHS <- rollapplyr(data, training_sample_len,
                      function(data) {
                        fit <- ugarchfit(specnorm, data)
                        res <- rugarch::residuals(fit, standardize = TRUE)
                        
                        # ASSIGN this calculation to 'hat'
                        hat <- sqrt(
                          fit@fit$coef['omega'] + 
                            fit@fit$coef['alpha1'] * tail(rugarch::residuals(fit), 1)^2 + 
                            fit@fit$coef['beta1'] * tail(sigma(fit), 1)^2
                        )
                        
                        # Now 'hat' exists for this calculation
                        draw <- sample(res, 20000, replace = TRUE)
                        draw_var <- quantile(draw, p_value)
                        
                        var <- draw_var * as.numeric(hat)
                        return(var)
                      })
testFHS <- last(lag(rollFHS, 1), 250)

################################################################################

testRealised <- last(data, 250)

var_predictions <- cbind(testHS,
                         testFHS,
                         testGarchNORM,
                         testGarchSNORM,
                         testGarchST)
colnames(var_predictions) <-
  c("HS", "FHS", "GARCH Norm", "GARCH SNORM", "GARCH ST")



excess_count <- function(var, true) {
  return(sum(ifelse(coredata(var) > coredata(true), 1, 0)))
}


sapply(var_predictions, excess_count, true = testRealised)

VaRTest(p_value, testRealised, testHS)

sapply(var_predictions, function(var) {
  c(
    "Kupiec"=VaRTest(p_value, testRealised, var)$uc.Decision,
    "Christoffersen"=VaRTest(p_value, testRealised, var)$cc.Decision
  )
})

ggplot(testRealised, aes(index(testRealised), indeks)) +
  geom_line(aes(y = testGarchNORM, colour = "Garch NORM"), size = 1) +
  geom_line(aes(y = testGarchSNORM, colour = "Garch SNORM"), size = 1) +
  geom_line(aes(y = testGarchST, colour = "Garch ST"), size = 1) +
  geom_line(aes(y = testHS, colour = "HS"), size = 1) +
  geom_line(aes(y = testFHS, colour = "FHS"), size = 1) +
  geom_point(aes(y = testRealised), size = 1) +
  scale_x_date(date_minor_breaks = "1 day") +  scale_colour_manual(
    "",
    breaks = c("Garch NORM", "Garch SNORM", "Garch ST", "HS", "FHS"),
    values = c("red", "green", "blue", "yellow", "brown")
  ) +
  xlab("") + ylab("Returns and VaRs")

# The quality of the models changes over time because market risk is not constant. Most methods yield similar results during calm periods, 
#but significant differences emerge in the severity and accuracy of estimates during phases of high volatility.

#Historical Simulation (HS) is fundamentally weak in dynamic markets because it produces a nearly constant VaR that cannot react to sudden shifts in market regimes, 
#often leading to a severe underestimation of risk during the onset of a crisis. In contrast, GARCH-based approaches perform better because 
#they treat volatility as a time-varying process, updating the VaR daily as market conditions evolve. 
#However, a standard GARCH model with a Normal distribution assumption can still be overly optimistic, 
#as real-world financial returns exhibit leptokurtosis (fat tails) that the normal distribution fails to capture.

Ultimately, methods that incorporate heavier tails or combine volatility filtering with the empirical shock distribution—such as Filtered Historical Simulation (FHS)—tend to be the most robust. These approaches allow the model to adjust quickly during stress periods while better reflecting the probability of extreme losses seen in historical data.

################################################################################
# Exercise 1.2
################################################################################
library(ROCR)
library(randomForest)
library(xgboost)
library(scorecard)

data <- read.csv("default_data.csv",
                 na.strings = "?",
                 stringsAsFactors = T)
str(data)

data <- data[complete.cases(data), ]

data <- droplevels(data)

data$default <- factor(data$default, levels = c(0, 1), labels = c("no", "yes"))

table(data$default)

set.seed(123456)
d = sort(sample(nrow(data), nrow(data) * .6))
train <- data[d, ]
test <- data[-d, ]

min_p <- 0.01 

for (v in names(train)) {
  if (is.factor(train[[v]]) && v != "default") {
    
    tab <- table(train[[v]])
    rare_levels <- names(tab)[tab / sum(tab) < min_p] 
    
    train[[v]] <- as.character(train[[v]])
    train[[v]][train[[v]] %in% rare_levels] <- "other"
    train[[v]] <- factor(train[[v]])
    
    test[[v]] <- as.character(test[[v]])
    test[[v]][test[[v]] %in% rare_levels] <- "other"
    
    test[[v]][!(test[[v]] %in% levels(train[[v]]))] <- "other"
    test[[v]] <- factor(test[[v]], levels = levels(train[[v]]))
  }
}

model <- glm(default ~ ., data = train, family = binomial())
summary(model)

table(train$A5)
with(train, table(A4, A5))

# a bit confusing here but it seems that A5 does not add anything to the model with A4 already in, therfore I will drop A5

#################################################################
# Logistic regression
#################################################################
model_lr <- glm(default ~ . - A5, family = binomial(), data = train)
summary(model_lr)


predict <- predict(model_lr, type = 'response', newdata = train)

table(train$default, predict > 0.5)

ROCpred <- prediction(predict, train$default)
ROCperf <- performance(ROCpred, 'tpr', 'fpr')
plot(ROCperf)

auc <- performance(ROCpred, measure = "auc")
auc <- auc@y.values[[1]]
auc

predict_LR <- predict(model_lr, type = 'response', newdata = test)

table(test$A6)

table(test$default, predict_LR > 0.5)

ROCpred_t <- prediction(predict_LR, test$default)
ROCperf_t <- performance(ROCpred_t, 'tpr', 'fpr')
plot(ROCperf_t)

auc_t <- performance(ROCpred_t, measure = "auc")
auc_t <- auc_t@y.values[[1]]
auc_t

table(test$default, predict_LR > 0.2)
table(test$default, predict_LR > 0.7)

###########################################################
# Random Forest
###########################################################
library(randomForest)



rf_model <- randomForest(
  default ~ . - A5,
  data = train,
  ntree = 100,
  mtry = max(2, floor(sqrt(ncol(train) - 1))),
  nodesize = 10,     
  maxnodes = 10,     
  sampsize = floor(0.8 * nrow(train)),
  importance = TRUE
)

print(rf_model)
importance(rf_model)
varImpPlot(rf_model)


rf_prob_train <- predict(rf_model, newdata = train, type = "prob")[, "yes"]

table(train$default, rf_prob_train > 0.5)

ROCpred_rf <- prediction(rf_prob_train, train$default)
ROCperf_rf <- performance(ROCpred_rf, "tpr", "fpr")
plot(ROCperf_rf)

auc_rf <- performance(ROCpred_rf, measure = "auc")@y.values[[1]]
auc_rf

rf_prob_test <- predict(rf_model, newdata = test, type = "prob")[, "yes"]

table(test$default, rf_prob_test > 0.5)

ROCpred_rf_t <- prediction(rf_prob_test, test$default)
ROCperf_rf_t <- performance(ROCpred_rf_t, "tpr", "fpr")
plot(ROCperf_rf_t)

auc_rf_t <- performance(ROCpred_rf_t, measure = "auc")@y.values[[1]]
auc_rf_t

table(test$default, rf_prob_test > 0.2)
table(test$default, rf_prob_test > 0.7)

###########################################################
# XGBOOST
###########################################################

library(xgboost)
library(Matrix)

x_train <- sparse.model.matrix(default ~ . - A5, data = train)[, -1] 
x_test  <- sparse.model.matrix(default ~ . - A5, data = test)[, -1]

y_train <- ifelse(train$default == "yes", 1, 0)
y_test  <- ifelse(test$default  == "yes", 1, 0)

dtrain <- xgb.DMatrix(data = x_train, label = y_train)
dtest  <- xgb.DMatrix(data = x_test,  label = y_test)

params <- list(
  booster = "gbtree",
  objective = "binary:logistic",
  eval_metric = "auc",
  eta = 0.05,           
  max_depth = 4,       
  min_child_weight = 10, 
  subsample = 0.8,       
  colsample_bytree = 0.8,
  gamma = 0.2,       
  lambda = 1.0,      
  alpha = 0.0 
)

watchlist <- list(train = dtrain, test = dtest)

xgb_model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 3000,
  watchlist = watchlist,
  early_stopping_rounds = 50,
  verbose = 1
)

pred_train <- predict(xgb_model, dtrain)
pred_test  <- predict(xgb_model, dtest)

table(train$default, pred_train > 0.5)
table(test$default,  pred_test  > 0.5)

ROCpred_xgb  <- prediction(pred_train, train$default)
ROCperf_xgb  <- performance(ROCpred_xgb, "tpr", "fpr")
plot(ROCperf_xgb)
auc_xgb <- performance(ROCpred_xgb, measure = "auc")@y.values[[1]]
auc_xgb

ROCpred_xgb_t <- prediction(pred_test, test$default)
ROCperf_xgb_t <- performance(ROCpred_xgb_t, "tpr", "fpr")
plot(ROCperf_xgb_t)
auc_xgb_t <- performance(ROCpred_xgb_t, measure = "auc")@y.values[[1]]
auc_xgb_t

table(test$default, pred_test > 0.2)
table(test$default, pred_test > 0.7)

#I would choose the random forest model because it has the highest out-of-sample AUC, which shows it’s better at picking up on the tricky, 
#non-linear patterns in the credit data compared to a simple logistic regression.

#For the threshold, I’d set it at 0.2. In the world of bank loans, missing a default (false negative) is way more expensive than accidentally 
#rejecting a good customer (false positive). At 0.2, the model only misses 6 defaults while catching 135 of them, which is a great result for staying safe. 
#Even though this means more "false alarms," the bank can just double-check those files manually. This 0.2 level is a smart, risk-averse choice for avoiding big losses, 
#though a huge bank might be willing to raise the threshold a bit if they aren't as worried about a few bad loans.





