################################################################################
#          				         Applied  Finance
#                           Risk modelling
#          					          2022/2023
#                   course intructor: Mateusz Buczynski
#          		University of Warsaw, Faculty of Economic Sciences
################################################################################
# 0. Prerequisites
################################################################################

# install new packages

install.packages("xts")
install.packages("utils")
install.packages("ggplot2")

# market risk
install.packages("rugarch")
install.packages("GAS")

# credit risk
install.packages('scorecard')

# operational risk
install.packages("OpVaR") # highly recommend to install from binary, source takes a lot of time

library(xts)
library(ggplot2)
library(utils)
library(rugarch)
library(GAS)




# lets change the LC_TIME option to English
Sys.setlocale("LC_TIME", "English")


# setting the working directory
setwd("...")

################################################################################
# 1. Market risk
################################################################################

################################################################################
# Setting up an experiment

# reading the data in, then converting it to xts format. this time we will use
# WIG20 price quotations, downloaded from stooq.pl
index_data <- read.csv("wig.csv", stringsAsFactors = F)
index_data.xts <- xts(index_data[,-1],
                      as.Date(index_data[, 1], "%Y-%m-%d"))


# we have to set some parameters for Value-at-Risk estimation. First of them
# is p-value, which is a significance level (1 - confidence level) for our
# estimates. Basically the larger this number the lower the probability that we
# will lose less than VaR.
# Another parameter is forecast horizon, which depicts how many observations do
# we want to include in the testing sample
p_value <- 0.025
forecast_horizon <- 250

# calculation of log returns (based on close prices)
log_returns <- diff(log(index_data.xts$Close), lag = 1)

# for the whole sample (training + testing) we will use data from 2008 up to end
# of 2011
data <- log_returns["2008/2011"]

# such data sample already includes the testing sample
nrow(data)

# we need to calculate how many training examples we will have, assuming the data
# sample and foorecast horizon we have
training_sample_len <- nrow(data) - forecast_horizon


# plotting the data with an event that shows us the first observation in testing
# sample
plot(data)
addEventLines(
  events = xts("testing sample", index(data[nrow(data) - forecast_horizon + 1])),
  col = "red",
  srt = 270,
  pos = 4
)

################################################################################
# Modeling
 

# Historical simulation


# First of the models is historical simulation. The simples approach assumes that
# the VaR for each prediction is a quantile (equal to p_value) of the training 
# sample. We will use moving (not expanding) window approach to calculate 
# quantiles for each timestep in testing sample
rollHS <- rollapplyr(data, training_sample_len,
                     function(w) {
                       quantile(w, p_value)
                     })

# we have to lag the output vector, because the VaR predictions are set on the 
# day of estimation, whereas we want them to illustrate the forecast for the 
# next timestep
testHS <- last(lag(rollHS, 1), 250)


# GARCH(1,1) with normal distribution

# GARCH model specification - we have to specify variance model (GARCH setting),
# mean model (ARMA setting, in our case nonpresent) and distribution model of the
# error term.
specnorm <-
  ugarchspec(
    variance.model = list(model="sGARCH", garchOrder=c(1, 1)),
    mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
    distribution.model = 'norm'
  )

# Rolling window approach estimation - same approach as the last time, we fit the
# model to the training sample and obtain VaR estimates for the next timestep.
# This time it is a little bit easier as we have a handy helping function from
# the package itself.
# 
# VaR_t+1 = mu + sigma_t+1 * quantile(dist, p_val)
rollnorm <- ugarchroll(
  specnorm,
  data,
  n.ahead = 1,
  forecast.length = forecast_horizon,
  refit.every = 1,
  refit.window = 'moving',
  keep.coef = TRUE,
  calculate.VaR = TRUE,
  VaR.alpha = p_value
)

# VaR estimation for testing period - in the forecast object of out rolling
# forecast we can find forecasts of conditional variance and VaR estimates. As
# we are the most interested in the latter, we can create an xts object with them
testGarchNORM <- xts(rollnorm@forecast$VaR,
                     as.Date(rownames(rollnorm@forecast$VaR)))[, 1]

# we can also plot these conditional variance forecasts to see whether 
# everything is okay with our model
plot(cbind(last(data, 250), rollnorm@forecast$density$Sigma))


# GARCH(1,1) with skewed normal distribution

# GARCH model specification
specSnorm <-
  ugarchspec(
    variance.model = list(model="sGARCH", garchOrder=c(1, 1)),
    mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
    distribution.model = 'snorm'
  )

# Rolling window approach estimation
rollSnorm <-
  ugarchroll(
    specSnorm,
    data,
    n.ahead = 1,
    forecast.length = forecast_horizon,
    refit.every = 1,
    refit.window = 'moving',
    keep.coef = TRUE,
    calculate.VaR = TRUE,
    VaR.alpha = p_value
  )

#VaR estimation for testing period
testGarchSNORM <- xts(rollSnorm@forecast$VaR,
                      as.Date(rownames(rollSnorm@forecast$VaR)))[, 1]

# we can also plot these conditional variance forecasts to see whether 
# everything is okay with our model
plot(cbind(last(data, 250), rollSnorm@forecast$density$Sigma))


# GARCH(1,1) with skewed t distribution

# GARCH model specification
specSt <-
  ugarchspec(
    variance.model = list(model="sGARCH", garchOrder=c(1, 1)),
    mean.model = list(armaOrder = c(0, 0), include.mean = FALSE),
    distribution.model = 'sstd'
  )

# Rolling window approach estimation
rollst <-
  ugarchroll(
    specSt,
    data,
    n.ahead = 1,
    forecast.length = forecast_horizon,
    refit.every = 1,
    refit.window = 'moving',
    keep.coef = TRUE,
    calculate.VaR = TRUE,
    VaR.alpha = p_value
  )

#VaR estimation for testing period
testGarchST <- xts(rollst@forecast$VaR,
                   as.Date(rownames(rollnorm@forecast$VaR)))[, 1]

# we can also plot these conditional variance forecasts to see whether 
# everything is okay with our model
plot(cbind(last(data, 250), rollst@forecast$density$Sigma))

# Filtered Historical Simulation (by GARCH(1,1))

rollFHS <- rollapplyr(data, training_sample_len,
                      function(data) {
                        # we are fitting a normal GARCH(1, 1) model to the current window
                        fit <- ugarchfit(specnorm, data)
                        # then we standardize the residuals with the conditional variance estimates z_t = (y_t - mu)/sigma_t
                        res <- rugarch::residuals(fit, standardize = T)
                        # then we calculate the forecast of conditional variance for the next timestep sigma_t+1 = omega + alpha * y_t^2 + beta * sigma_t^2
                        hat <-
                          sqrt(
                            fit@fit$coef['omega'] + fit@fit$coef['alpha1'] * tail(rugarch::residuals(fit), 1) ^
                              2 + fit@fit$coef['beta1'] * tail(sigma(fit), 1) ^ 2
                          )
                        # we are drawing a large number of standardized residuals from our window
                        draw <- sample(res, 20000, replace = T)
                        # from such sample we pick a standardized residual that is a pvalue quantile that we are interested in
                        draw_var <- quantile(draw, p_value)
                        # and we use a standard var equation VaR_t+1 = mu + sigma_t+1*quantile(z_1:z_t, p_value)
                        var <- draw_var * as.numeric(hat)
                          return(var)
                      })

# same as in the case of historical simulation - we have to shift the vector so
# that we obtain forecast for the next (not current) timestep
testFHS <- last(lag(rollFHS, 1), 250)

################################################################################
# Basic assessment of VaR quality

# let's create a vector of realizations of rate of return in the testing sample
testRealised <- last(data, 250)

# and the forecasts of VaR that we have just calculated
var_predictions <- cbind(testHS,
                         testFHS,
                         testGarchNORM,
                         testGarchSNORM,
                         testGarchST)
colnames(var_predictions) <-
  c("HS", "FHS", "GARCH Norm", "GARCH SNORM", "GARCH ST")


# function to calculate basic number of exceptions
excess_count <- function(var, true) {
  # if VaR > true realizaion (lower in absolute terms) then we have an exception
  return(sum(ifelse(coredata(var) > coredata(true), 1, 0)))
}

# we apply this function to each column in out VaR estimates object
sapply(var_predictions, excess_count, true = testRealised)

# we can also run Kupiec and Christoffersen tests to see whether conditional and
# unconditional hypotheses should be rejected or not
VaRTest(p_value, testRealised, testHS)

# let's apply this function to each of our VaR forecasts
sapply(var_predictions, function(var) {
  c(
    "Kupiec"=VaRTest(p_value, testRealised, var)$uc.Decision,
    "Christoffersen"=VaRTest(p_value, testRealised, var)$cc.Decision
  )
})

# plot with VaRs
ggplot(testRealised, aes(index(testRealised), indeks)) +
  geom_line(aes(y = testGarchNORM, colour = "Garch NORM"), size = 1) +
  geom_line(aes(y = testGarchSNORM, colour = "Garch SNORM"), size = 1) +
  geom_line(aes(y = testGarchST, colour = "Garch ST"), size = 1) +
  geom_line(aes(y = testHS, colour = "HS"), size = 1) +
  geom_line(aes(y = testFHS, colour = "FHS"), size = 1) +
  geom_point(aes(y = testRealised), size = 1) +
  scale_x_date(date_minor_breaks = "1 day") +  scale_colour_manual(
    "",
    breaks = c("Garch NORM", "Garch SNORM", "Garch ST", "HS", "FHS"),
    values = c("red", "green", "blue", "yellow", "brown")
  ) +
  xlab("") + ylab("Returns and VaRs")



################################################################################
# 2. Credit risk
################################################################################
# based on: https://cran.r-project.org/doc/contrib/Sharma-CreditScoring.pdf

################################################################################
# Data preparation

rm(list = ls())
library(ROCR)
library(randomForest)
library(xgboost)
library(scorecard)

# read the data on german credit applications
data <- read.csv("german_credit.csv", stringsAsFactors = T)

# let's see what's in the dataset
str(data)

# converting variables to necessary types
data$property <- as.factor(data$property)
data$age <- as.numeric(data$age)
data$credit_amount <- as.double(data$credit_amount)

# example of binning
data$credit_amount <-
  as.factor(ifelse(
    data$credit_amount <= 2500, '0-2500',
    ifelse(data$credit_amount <= 5000, '2501-5000', '5000+')
  ))

# let's delete any rows with missing data (this is a common situation with 
# credit risk datasets)
data <- data[complete.cases(data),]

# data division into training and testing sample
set.seed(123456)
d = sort(sample(nrow(data), nrow(data) * .6))
train <- data[d, ]
test <- data[-d, ]


################################################################################
# Modeling

# we will fit the logistic regression model to the whole dataset. R is such a
# straightforward tool there that it doesn't require us to convert character 
# (factor) columns into numerical ones, it does it on its own
model_lr <- glm(default ~ ., data = train, family = binomial())
summary(model_lr)

# let's see how our model predicts defaulting entities
predict <- predict(model_lr, type = 'response', newdata = train)

# confusion matrix for training set
table(train$default, predict > 0.5)

# ROC Curve - tells us how TPR and FPR change when we change the threshold
ROCpred <- prediction(predict, train$default)
ROCperf <- performance(ROCpred, 'tpr', 'fpr')
plot(ROCperf)

# AUC value
auc <- performance(ROCpred, measure = "auc")
auc <- auc@y.values[[1]]
auc


# now let's see how that changes on testing sample
predict_LR <- predict(model_lr, type = 'response', newdata = test)

# confusion matrix for training set
table(test$default, predict_LR > 0.5)

# ROC Curve
ROCpred_t <- prediction(predict_LR, test$default)
ROCperf_t <- performance(ROCpred_t, 'tpr', 'fpr')
plot(ROCperf_t)

# AUC value
auc_t <- performance(ROCpred_t, measure = "auc")
auc_t <- auc_t@y.values[[1]]
auc_t



# influence of the threshold on the default criterion
table(test$default, predict_LR > 0.2)
table(test$default, predict_LR > 0.7)


################################################################################
# Scorecard - https://cran.r-project.org/web/packages/scorecard/vignettes/demo.html

library(scorecard)
# The weight of evidence tells the predictive power of an independent variable 
# in relation to the dependent variable. It is generally described as a measure 
# of the separation of good and bad customers.

# Automatic Optimal WoE binning
binned_data = woebin(train, y="default")

# Converting train and test into WoE values: all values of each attributes
# are replaced by their respective WoE values already calculated
train_woe = woebin_ply(train, binned_data)
test_woe = woebin_ply(test, binned_data)

# Logistic Regression applied to the training data that we converted to WoE values:
m1 = glm( default ~ ., family = binomial(), data = train_woe)

# Show estimated coefficients and significance level of each attribute:
summary(m1)

# Scorecard Scaling & final card:
card = scorecard(bins = binned_data, m1, points0 = 1000, odds0 = 50, pdo = 20)

card$credit_amount
card$age


################################################################################
# 3. Operational risk
################################################################################

# based on: https://cran.r-project.org/web/packages/OpVaR/vignettes/OpVaR_vignette.html
rm(list = ls())
library(OpVaR)

# We will use a dataset provided by the authors of the package as such datasets
# are hardly available
data(lossdat)

# we hava a 4 datasets of losses from different periods
# in each we have Loss & Period
head(lossdat[[1]])
head(lossdat[[2]])
head(lossdat[[3]])
head(lossdat[[4]])

hist(lossdat[[1]]$Loss)

#let's put all the data in a list
opriskmodel = list()
for (i in 1:length(lossdat)) {
  opriskmodel[[i]] = list()
}

# Fitting Loss Frequency Distributions
# There are two options for modeling loss frequencies: the Poisson and negative 
# binomial distribution. Loss frequency models are fitted using the fitFreqdist 
# command and take into account the discrete time period classification in the 
# data.

### Fit Frequency Distribution
opriskmodel[[1]]$freqdist = fitFreqdist(lossdat[[1]], "pois")
opriskmodel[[2]]$freqdist = fitFreqdist(lossdat[[2]], "pois")
opriskmodel[[3]]$freqdist = fitFreqdist(lossdat[[3]], "nbinom")
opriskmodel[[4]]$freqdist = fitFreqdist(lossdat[[4]], "nbinom")

# Fitting Loss Severity Distributions
# For loss severities three types of models are available:
# ?plain? - a single distribution (e.g., gamma, lognormal, Weibull)
# ?spliced? - a flexible combination of two distributions and a threshold 
# (maximum likelihood estimation/Bayesian estimation # as in Ergashev, 
# Mittnik and Sekeris, 2013)
# ?mixing? - a dynamically weighted mixture model as in Frigessi et al., 2002.


### fit Severity Distributions
opriskmodel[[1]]$sevdist = fitPlain(lossdat[[1]], "gamma")
opriskmodel[[2]]$sevdist = fitPlain(lossdat[[2]], "weibull")
opriskmodel[[3]]$sevdist = fitSpliced(lossdat[[3]], "gamma", "gpd", method =
                                        "Fixed", thresh = 2000)
opriskmodel[[4]]$sevdist = fitSpliced(lossdat[[4]], "gamma", "gpd", method =
                                        "Fixed", thresh = 2000)


# Evaluating Model Fit
# Goodness of fit tests are available for the continuous loss severity models
# (Anderson-Darling, Cramer-von Mises, Kolmogorov-Smirnov test) as well as
# for the discrete loss frequency models (Chi square test):

### Test Model Fit (Severities)
goftest(lossdat[[3]], opriskmodel[[3]]$sevdist)

### Plot of estimated distirbution - can be non-continous & non-diffretiable
plot(opriskmodel[[3]]$sevdist)
lines(density(lossdat[[3]]$Loss))

### Test Model Fit (Frequencies)
goftest(lossdat[[3]], opriskmodel[[3]]$freqdist)

# Total Loss Estimation by Monte Carlo Simulation
# Given a correctly specified opriskmodel, total loss for the single cells 
# can be estimated by Monte Carlo simulation (mcSim function).
# The simulation result should be stored, so that afterwards Value-at-Risk 
# can be determined by the VaR function. Especially depending on complex 
# dependency or loss severity models, the simulation can be time consuming.


### Monte Carlo Simulation
mc_out = mcSim(opriskmodel, 10000, verbose = TRUE)

### Value-at-Risk Calculation
VaR(mc_out, .975)


# Single Loss Approximation
# A closed form approximation of Value-at-Risk can also be determined using a 
# tail index based quantile approximation assuming independence of the loss 
# severity and loss frequency. This procedure is numerically fast and can e.g.,
# be used for validating Monte Carlo simualtion based risk figures.

### Benchemark: Value-at-Risk by Single Loss Approximation
sla(opriskmodel, .95)

